# Machine Learning from Scratch â€” Boosting Didactique

> Auteur : **Manda Rostand**  
> Profession : Data Scientist (5 ans d'expÃ©rience)  
> Contact : rostandsurel@yahoo.com

---

Ce dÃ©pÃ´t GitHub a pour vocation d'Ãªtre un rÃ©fÃ©rentiel **Ã©volutif et pÃ©dagogique** dÃ©diÃ© Ã  lâ€™apprentissage et Ã  lâ€™implÃ©mentation des principaux algorithmes de boosting. Il sâ€™adresse aux Ã©tudiants, professionnels ou passionnÃ©s de machine learning qui souhaitent **comprendre les fondements mathÃ©matiques et algorithmiques** de ces modÃ¨les en les **reproduisant from scratch**.

---

## ğŸš€ Objectif

Lâ€™objectif principal est de **favoriser la comprÃ©hension approfondie** de modÃ¨les de boosting en partant de zÃ©ro :
- en dÃ©cortiquant leurs mÃ©canismes internes,
- en expliquant les intuitions mathÃ©matiques et algorithmiques,
- et en les implÃ©mentant sans dÃ©pendre de bibliothÃ¨ques toutes faites comme scikit-learn ou XGBoost directement.

---

## ğŸ“š Contenu du dÃ©pÃ´t

### ğŸ”¹ [XGBoost](./xgboost_from_scratch)
- Cours complet : boosting, gradient, loss functions, rÃ©gularisation
- DÃ©rivation mathÃ©matique de lâ€™algorithme
- ImplÃ©mentation Ã©tape par Ã©tape en Python
- Visualisation des arbres
- Cas dâ€™usage simple (classification ou rÃ©gression)

### ğŸ”¹ [CatBoost](./catboost_from_scratch)
- Cours sur le traitement des variables catÃ©gorielles, encodage ordonnÃ©
- SpÃ©cificitÃ©s de l'algorithme : target statistics, permutations
- ImplÃ©mentation complÃ¨te from scratch
- Comparaison avec XGBoost

### ğŸ”¹ [LightGBM](./lightgbm_from_scratch)
- ThÃ©orie sur histogram-based decision trees et leaf-wise growth
- Optimisations mÃ©moire et temps
- ImplÃ©mentation avec gestion des bins
- Benchmark basique

---

## ğŸ§  MÃ©thodologie

Chaque sous-rÃ©pertoire contient :
- Un dossier `cours/` contenant des fichiers `.md` avec :
  - DÃ©finitions formelles
  - Formules clÃ©s (dÃ©rivÃ©es, gradients, hessians, etc.)
  - Explications Ã©tape par Ã©tape
- Un dossier `implementation/` contenant :
  - Le code Python `from scratch`
  - Des blocs bien commentÃ©s
  - Des tests sur des jeux de donnÃ©es jouets
- Des illustrations et des schÃ©mas seront ajoutÃ©s pour mieux visualiser les concepts.

---

## ğŸ“Œ Pourquoi ce dÃ©pÃ´t ?

La majoritÃ© des projets ML reposent sur des bibliothÃ¨ques haut niveau. Ce dÃ©pÃ´t rÃ©pond Ã  un besoin diffÃ©rent :
- **DÃ©mythifier** les modÃ¨les complexes
- **DÃ©velopper une intuition forte**
- **Se prÃ©parer Ã  des entretiens techniques ML/DS**
- **Mieux comprendre les hyperparamÃ¨tres et les choix dâ€™implÃ©mentation**

---

## ğŸ› ï¸ Ã€ venir

- Ajout de notebooks Jupyter pour tester les implÃ©mentations
- Visualisation dynamique des arbres
- Comparaison des performances vs bibliothÃ¨ques standards
- Extensions : AdaBoost, GradientBoosting classique, etc.

---

## âš–ï¸ Licence

Ce dÃ©pÃ´t est sous licence MIT. Vous Ãªtes libres de l'utiliser, le modifier ou le redistribuer avec mention de l'auteur.

Voir [LICENSE](./LICENSE) pour plus d'informations.

---

## ğŸ™Œ Remerciements

Merci Ã  la communautÃ© open source pour lâ€™inspiration continue. Ce projet est Ã©galement un outil dâ€™auto-formation et de transmission.

---

## ğŸ“© Contact

Si vous avez des questions, suggestions ou souhaitez collaborer :

- ğŸ“§ Email : rostandsurel@yahoo.com
- ğŸ’¼ LinkedIn : [https://www.linkedin.com/in/rostand-surel/](https://www.linkedin.com/in/rostand-surel/)

---
